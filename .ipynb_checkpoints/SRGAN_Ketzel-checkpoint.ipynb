{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Karko93/CIL-GAN-Project/blob/master/SRGAN_Ketzel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRCrxEEf13XQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv \n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.utils.data as datatorch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "#from google.colab import drive\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg19\n",
    "import math\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = pd.read_csv(\"cosmology_aux_data_170429/labeled.csv\", dtype = np.int64).to_numpy()\n",
    "scored_data = pd.read_csv(\"cosmology_aux_data_170429/scored.csv\").to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dir = 'cosmology_aux_data_170429/labeled'\n",
    "query_dir = 'cosmology_aux_data_170429/query'\n",
    "scored_dir = 'cosmology_aux_data_170429/scored'\n",
    "labeled_files = os.listdir(labeled_dir)\n",
    "scored_files = os.listdir(scored_dir)\n",
    "query_files = os.listdir(query_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_array,dir, hr_shape, mode = 'train', labels = None):\n",
    "        self.files = file_array\n",
    "        self.mode = mode\n",
    "        self.labels  = labels\n",
    "        self.dir = dir\n",
    "        hr_height, hr_width = hr_shape\n",
    "        # Transforms for low resolution images and high resolution images\n",
    "        self.lr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ]\n",
    "        )\n",
    "        self.hr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.dir, self.files[index]))\n",
    "        #img = imread(os.path.join(self.dir, self.files[index])).astype(np.float)\n",
    "        #img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        #img =torch.stack([img,img,img],0)\n",
    "        #img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        img_lr = self.lr_transform(img)\n",
    "        img_hr = self.hr_transform(img)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            mask = np.isin(self.labels[:,0], int(self.files[index][:-4]))\n",
    "            label = self.labels[mask,1]\n",
    "            \n",
    "            return img_lr,img_hr,label\n",
    "        else:\n",
    "            return img_lr,img_hr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_shape = (1000, 1000)\n",
    "scored_dataset = ImageDataset(scored_files, scored_dir, hr_shape=hr_shape, mode = 'train', labels =scored_data)\n",
    "labeled_dataset = ImageDataset(labeled_files, labeled_dir, hr_shape=hr_shape, mode = 'train', labels =labeled_data)\n",
    "query_dataset = ImageDataset(query_files, query_dir, hr_shape=hr_shape, mode = 'test', labels =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.feature_extractor(img)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features, 0.8),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features, 0.8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU())\n",
    "\n",
    "        # Residual blocks\n",
    "        res_blocks = []\n",
    "        for _ in range(n_residual_blocks):\n",
    "            res_blocks.append(ResidualBlock(64))\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        # Second conv layer post residual blocks\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8))\n",
    "\n",
    "        # Upsampling layers\n",
    "        upsampling = []\n",
    "        for out_features in range(2):\n",
    "            upsampling += [\n",
    "                # nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 256, 3, 1, 1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "                nn.PReLU(),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsampling)\n",
    "\n",
    "        # Final output layer\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4)+1, int(in_width / 2 ** 4)+1 ####\n",
    "        #self.output_shape = (1, patch_h, patch_w)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"saved_images\", exist_ok=True)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size =1\n",
    "epochs = 4\n",
    "logstep = int(10000 // batch_size)\n",
    "start_epoch = 0\n",
    "checkpoint_interval= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorResNet(in_channels=3, out_channels=3, n_residual_blocks=16).to(device)\n",
    "discriminator = Discriminator(input_shape=(3, *hr_shape)).to(device)\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Set feature extractor to inference mode\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_content = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "labeled_Dataloader = datatorch.DataLoader(dataset=labeled_dataset, shuffle=False, batch_size=batch_size)\n",
    "scored_Dataloader = datatorch.DataLoader(dataset=scored_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\"))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, (lr_img, hr_img, label) in enumerate(scored_Dataloader):\n",
    "    lr_img,hr_img = torch.cat([lr_img,lr_img,lr_img],1).cuda(),torch.cat([hr_img,hr_img,hr_img],1).cuda()\n",
    "    print(lr_img.size())\n",
    "\n",
    "    valid = torch.Tensor(np.ones((lr_img.size(0), *discriminator.output_shape))).cuda()\n",
    "    fake = torch.Tensor(np.zeros((hr_img.size(0), *discriminator.output_shape))).cuda()\n",
    "\n",
    "\n",
    "    # ------------------\n",
    "    #  Train Generators\n",
    "    # ------------------\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Generate a high resolution image from low resolution input\n",
    "    gen_hr = generator(lr_img)\n",
    "\n",
    "    #print(lr_img.size(), gen_hr.size(),discriminator(gen_hr).size(), valid.size(),lr_img.size(0))\n",
    "    # Adversarial loss\n",
    "    loss_GAN = criterion_GAN(discriminator(gen_hr), valid)\n",
    "\n",
    "    # Content loss\n",
    "    print(gen_hr.size(), hr_img.size())\n",
    "    gen_features = feature_extractor(gen_hr)\n",
    "    real_features = feature_extractor(hr_img)\n",
    "    loss_content = criterion_content(gen_features, real_features.detach())\n",
    "    # Total loss\n",
    "    loss_G = loss_content + 1e-3 * loss_GAN\n",
    "\n",
    "    loss_G.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "# ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "\n",
    "    # Loss of real and fake images\n",
    "\n",
    "    print(discriminator(gen_hr).size())\n",
    "    loss_real = criterion_GAN(discriminator(hr_img), valid)\n",
    "    loss_fake = criterion_GAN(discriminator(gen_hr.detach()), fake)\n",
    "    # Total loss\n",
    "    loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "    loss_D.backward()\n",
    "    optimizer_D.step()\n",
    "    print(idx, len(scored_Dataloader), loss_D.item(), loss_G.item())\n",
    "    \n",
    "    batches_done = epoch * len(dataloader) + idx\n",
    "        if batches_done % 100 == 0:\n",
    "            # Save image grid with upsampled inputs and SRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\n",
    "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
    "            img_grid = torch.cat((imgs_lr, gen_hr), -1)\n",
    "            save_image(img_grid, \"images/%d.png\" % batches_done, normalize=False)\n",
    "\n",
    "if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "    # Save model checkpoints\n",
    "    torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n",
    "    torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" % epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    for idx,(lr_img,hr_img,label) in enumerate(labeled_Dataloader):\n",
    "        lr_img,hr_img,label = lr.cuda(),hr.cuda(),label.cuda()\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.Tensor(np.ones((lr_img.size(0), *discriminator.output_shape)))\n",
    "        fake = torch.Tensor(np.zeros((hr_img.size(0), *discriminator.output_shape)))\n",
    "        break\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a high resolution image from low resolution input\n",
    "        gen_hr = generator(imgs_lr)\n",
    "\n",
    "        # Adversarial loss\n",
    "        loss_GAN = criterion_GAN(discriminator(gen_hr), valid)\n",
    "\n",
    "        # Content loss\n",
    "        gen_features = feature_extractor(gen_hr)\n",
    "        real_features = feature_extractor(imgs_hr)\n",
    "        loss_content = criterion_content(gen_features, real_features.detach())\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_content + 1e-3 * loss_GAN\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss of real and fake images\n",
    "        loss_real = criterion_GAN(discriminator(imgs_hr), valid)\n",
    "        loss_fake = criterion_GAN(discriminator(gen_hr.detach()), fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        sys.stdout.write(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, epochs, i, len(labeled_Dataloader), loss_D.item(), loss_G.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(labeled_Dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            # Save image grid with upsampled inputs and SRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\n",
    "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
    "            img_grid = torch.cat((imgs_lr, gen_hr), -1)\n",
    "            save_image(img_grid, \"images/%d.png\" % batches_done, normalize=False)\n",
    "    break\n",
    "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
    "        \n",
    "        # Save model checkpoints\n",
    "        torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" % epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xx = torch.rand(1,1,20,20)\n",
    "y =torch.cat([xx,xx,xx],1)\n",
    "print(xx.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNBLr2sDRWlIi38RJQmeIqf",
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
